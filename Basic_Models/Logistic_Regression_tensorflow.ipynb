{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Models - Logistic Regression\n",
    "A logistic regression learning algorithm using tensorflow mnist dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data \n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x110e47630>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11354beb8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x1142f4710>)\n"
     ]
    }
   ],
   "source": [
    "print(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist_dataset input data :  [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "Mnist_dataset targeted data :  [[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Display an image from mnist dataset\n",
    "\n",
    "def gen_image(arr):\n",
    "    twoD = (np.reshape(arr,(28,28))* 255).astype(np.uint8)\n",
    "    plt.imshow(twoD, interpolation='nearest')\n",
    "    return plt.show()\n",
    "\n",
    "\n",
    "# Let's get the data from dataset.\n",
    "batch_xs, batch_ys = mnist.test.next_batch(10)\n",
    "print(\"Mnist_dataset input data : \",batch_xs)\n",
    "print(\"Mnist_dataset targeted data : \", batch_ys)\n",
    "\n",
    "# HERE #\n",
    "# batch_xs : An input data for training\n",
    "# batch_ys : An targeted data for model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot our image\n",
    "gen_image(batch_xs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 100\n",
    "batch_size = 20\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholder in tensorflow for storing image and it's desired output\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image has shape 28 x 28 = 784\n",
    "y = tf.placeholder(tf.float32, [None, 10]) # mnist dataset has only 10 classes. 0 to 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression follows similar formula as linear regression. \n",
    "***\n",
    "$ y = Wx + b $<br>\n",
    "<br>\n",
    "where W : Weights of the model , b : Bias of the model<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weights and biases. Let's initalize it to zero. \n",
    "W = tf.Variable(tf.zeros([784,10]), name='weights')\n",
    "# W = tf.Variable(tf.random_normal(shape=[784,10], stddev = 0.01), name = \"weights\")\n",
    "b = tf.Variable(tf.zeros([10]), name='Bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's time to construct a model now. \n",
    "# As we know, our model is similar to linear regression model. Let's write it down.\n",
    "\n",
    "pred_Y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error reduction function A.K.A. loss function\n",
    "\n",
    ">We have predicted value from our model is 'pred_Y', which should be same as actual value 'y'. _But_ as our model is undertraining, we might expect different value. <br> \n",
    "So, to reduce this error, we need to feed our network with feedback mechanism. <br>\n",
    "Here, we uses mean square error (MSE) to reduce the loss. <br>\n",
    "![title](MSE.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred_Y), reduction_indices=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Optimizer\n",
    "<br>\n",
    "- _Gradient_ : It is multi-variable generalization vector of _derivative_ $dy/dx$.<br>\n",
    "    - which means, rate of change of _y with respect to x_.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer uses to get slightly better and faster learning by updating the model parameters such as _Weights_ and _Bias_ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 Cost:   0.676055\n",
      "Epoch:  0002 Cost:   0.416618\n",
      "Epoch:  0003 Cost:   0.374715\n",
      "Epoch:  0004 Cost:   0.353241\n",
      "Epoch:  0005 Cost:   0.339711\n",
      "Epoch:  0006 Cost:   0.329803\n",
      "Epoch:  0007 Cost:   0.322519\n",
      "Epoch:  0008 Cost:   0.316584\n",
      "Epoch:  0009 Cost:   0.311570\n",
      "Epoch:  0010 Cost:   0.307551\n",
      "Epoch:  0011 Cost:   0.304089\n",
      "Epoch:  0012 Cost:   0.300892\n",
      "Epoch:  0013 Cost:   0.298159\n",
      "Epoch:  0014 Cost:   0.295765\n",
      "Epoch:  0015 Cost:   0.293571\n",
      "Epoch:  0016 Cost:   0.291664\n",
      "Epoch:  0017 Cost:   0.289673\n",
      "Epoch:  0018 Cost:   0.288168\n",
      "Epoch:  0019 Cost:   0.286753\n",
      "Epoch:  0020 Cost:   0.285205\n",
      "Epoch:  0021 Cost:   0.283909\n",
      "Epoch:  0022 Cost:   0.282651\n",
      "Epoch:  0023 Cost:   0.281570\n",
      "Epoch:  0024 Cost:   0.280325\n",
      "Epoch:  0025 Cost:   0.279387\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-12e8117e3d27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# Let's run optimizer and cost operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mdummy_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start Session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    # TRAINING\n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        # Batch wise training\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Let's run optimizer and cost operation\n",
    "            dummy_1, c = sess.run((optimizer, cost), feed_dict = {x: batch_xs, y:batch_ys})\n",
    "            \n",
    "            avg_cost += c/total_batch\n",
    "        \n",
    "        \n",
    "        # Log Steps\n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            print(\"Epoch: \", '%04d' % (epoch+1), \"Cost: \", \"{:9f}\".format(avg_cost))\n",
    "        \n",
    "    print(\"Congo, Model has been Trained\")\n",
    "    \n",
    "    \n",
    "    ###################\n",
    "    ## MODEL TESTING ##\n",
    "    ###################\n",
    "    \n",
    "    correct_pred = tf.equal(tf.arg_max(pred_Y, 1), tf.arg_max(y , 1))\n",
    "    \n",
    "    # Calculate accuracy or model\n",
    "\n",
    "    acc = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    print(\"Accuracy of Model: \", acc.eval({x:mnist.test.images, y: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
